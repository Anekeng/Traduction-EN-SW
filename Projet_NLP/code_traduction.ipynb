{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\new_nlpevn\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "from datasets import Dataset, DatasetDict, load_dataset\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, processors\n",
    "from tokenizers.normalizers import NFKC\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger la base sur Hugging Face \n",
    "ds = load_dataset(\"emuchogu/swahili-english-translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en DataFrame \n",
    "df = pd.DataFrame(ds("train"))\n",
    "# Sauvegarder en fichier CSV\n",
    "df.to_csv(\"swahili_english_translation.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees = pd.read_csv(\"swahili_english_translation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = donnees.head(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame(columns=[\"en\", \"ye\"])\n",
    "df_p[\"en\"] = df.apply(lambda row: row[\"input\"] if row.name % 2 == 0 else row[\"output\"], axis=1)\n",
    "df_p[\"ye\"] = df.apply(lambda row: row[\"output\"] if row.name % 2 == 0 else row[\"input\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1349</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>The people are outside.</td>\n",
       "      <td>Watu wako nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6272</td>\n",
       "      <td>8004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             en              ye\n",
       "count                     50000           50000\n",
       "unique                     1349            1343\n",
       "top     The people are outside.  Watu wako nje.\n",
       "freq                       6272            8004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>Mtu aliyepanda farasi anaruka juu ya ndege ili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>Mtu aliyepanda farasi anaruka juu ya ndege ili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>Watoto wakitabasamu na kutikisa kamera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>Watoto wakitabasamu na kutikisa kamera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
       "      <td>Mvulana anakimbia kwenye ubao wa kuteleza kati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      en  \\\n",
       "0      A person on a horse jumps over a broken down a...   \n",
       "1      A person on a horse jumps over a broken down a...   \n",
       "2                  Children smiling and waving at camera   \n",
       "3                  Children smiling and waving at camera   \n",
       "4      A boy is jumping on skateboard in the middle o...   \n",
       "...                                                  ...   \n",
       "49995                                 A man is sleeping.   \n",
       "49996                                 A man is sleeping.   \n",
       "49997                                 A man is sleeping.   \n",
       "49998                                 A man is sleeping.   \n",
       "49999                                 A man is sleeping.   \n",
       "\n",
       "                                                      ye  \n",
       "0      Mtu aliyepanda farasi anaruka juu ya ndege ili...  \n",
       "1      Mtu aliyepanda farasi anaruka juu ya ndege ili...  \n",
       "2                 Watoto wakitabasamu na kutikisa kamera  \n",
       "3                 Watoto wakitabasamu na kutikisa kamera  \n",
       "4      Mvulana anakimbia kwenye ubao wa kuteleza kati...  \n",
       "...                                                  ...  \n",
       "49995                          Mwanamume fulani amelala.  \n",
       "49996                          Mwanamume fulani amelala.  \n",
       "49997                          Mwanamume fulani amelala.  \n",
       "49998                          Mwanamume fulani amelala.  \n",
       "49999                          Mwanamume fulani amelala.  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon d'entraînement: 32000\n",
      "Taille de l'échantillon de validation: 8000\n",
      "Taille de l'échantillon de test: 10000\n"
     ]
    }
   ],
   "source": [
    "# Convertir le DataFrame en une liste de dictionnaires\n",
    "data_list = df_p.to_dict(orient='records')\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement, validation et test\n",
    "train, test = train_test_split(data_list, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "train, validation = train_test_split(train, test_size=0.2, random_state=42)  # 80% train, 20% validation\n",
    "\n",
    "print(f\"Taille de l'échantillon d'entraînement: {len(train)}\")\n",
    "print(f\"Taille de l'échantillon de validation: {len(validation)}\")\n",
    "print(f\"Taille de l'échantillon de test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train)\n",
    "validation_dataset = Dataset.from_list(validation)\n",
    "test_dataset = Dataset.from_list(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['en', 'ye'],\n",
      "        num_rows: 32000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['en', 'ye'],\n",
      "        num_rows: 8000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['en', 'ye'],\n",
      "        num_rows: 10000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Construire le DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_p[\"ye\"]\n",
    "pd.DataFrame(corpus).to_csv('corpus.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = df_p[\"en\"]\n",
    "pd.DataFrame(corpus2).to_csv('corpus2.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser un tokenizer basé sur WordPiece\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "# Ajouter des normalisations et des pré-tokenizers\n",
    "tokenizer.normalizer = NFKC()\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Configurer un entraîneur pour générer un vocabulaire\n",
    "trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=30000)\n",
    "\n",
    "# Charger un corpus et entraîner le tokenizer\n",
    "files = [\"corpus.txt\"]  \n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "# Définir un post-traitement \n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", 1), (\"[SEP]\", 2)]\n",
    ")\n",
    "# Sauvegarder le tokenizer\n",
    "tokenizer.save(\"TokenizerSW.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour l'anglais\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "\n",
    "tokenizer.normalizer = NFKC()\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=30000)\n",
    "\n",
    "files = [\"corpus2.txt\"] \n",
    "tokenizer.train(files, trainer)\n",
    "\n",
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[CLS] $A [SEP]\",\n",
    "    pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "    special_tokens=[(\"[CLS]\", 1), (\"[SEP]\", 2)]\n",
    ")\n",
    "tokenizer.save(\"TokenizerEN.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'M', '##tu', 'al', '##i', '##y', '##ep', '##and', '##a', 'far', '##a', '##si', 'an', '##ar', '##u', '##ka', 'ju', '##u', 'y', '##a', 'n', '##de', '##ge', 'il', '##i', '##y', '##o', '##v', '##un', '##j', '##ik', '##a', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tester le tokenizer\n",
    "encoded = tokenizer.encode(\"Mtu aliyepanda farasi anaruka juu ya ndege iliyovunjika.\")\n",
    "print(encoded.tokens)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ye_nlp = Tokenizer.from_file(\"TokenizerSW.json\")\n",
    "en_nlp = Tokenizer.from_file(\"TokenizerEN.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire Anglais: 2396\n",
      "Taille du vocabulaire Yemba: 2258\n"
     ]
    }
   ],
   "source": [
    "def yield_tokens(dataset, lang):\n",
    "    \"\"\"Générateur de tokens pour le vocabulaire.\"\"\"\n",
    "    for example in dataset:\n",
    "        yield example[lang].split()  # Tokenisation naïve par espaces\n",
    "\n",
    "# Construire le vocabulaire pour chaque langue\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "bos_token = \"<bos>\"\n",
    "eos_token = \"<eos>\"\n",
    "en_vocab = build_vocab_from_iterator(yield_tokens(train_data, \"en\"), specials= [unk_token, pad_token, bos_token, eos_token])\n",
    "ye_vocab = build_vocab_from_iterator(yield_tokens(train_data, \"ye\"), specials= [unk_token, pad_token, bos_token, eos_token])\n",
    "\n",
    "# Configurer l'index spécial pour <unk>\n",
    "en_vocab.set_default_index(en_vocab[\"<unk>\"])\n",
    "ye_vocab.set_default_index(ye_vocab[\"<unk>\"])\n",
    "\n",
    "# Vérification\n",
    "print(\"Taille du vocabulaire Anglais:\", len(en_vocab))\n",
    "print(\"Taille du vocabulaire Yemba:\", len(ye_vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index de 'the': 14\n",
      "Index de 'anaruka': 551\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'indexation de mots\n",
    "print(\"Index de 'the':\", en_vocab[\"the\"])  # Retourne l'index si le mot existe, sinon <unk>\n",
    "print(\"Index de 'anaruka':\", ye_vocab[\"anaruka\"])  # Mot en swalli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<bos>',\n",
       " '<eos>',\n",
       " 'is',\n",
       " 'man',\n",
       " 'The',\n",
       " 'outside.',\n",
       " 'A',\n",
       " 'are']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<bos>',\n",
       " '<eos>',\n",
       " 'Mwanamume',\n",
       " 'nje.',\n",
       " 'huyo',\n",
       " 'Watu',\n",
       " 'wako',\n",
       " 'fulani']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ye_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ye_vocab[unk_token] == en_vocab[unk_token]\n",
    "assert ye_vocab[pad_token] == en_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "ye_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 128, 4, 170, 14, 594]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"our\", \"riparian\", \"field\", \"is\", \"near\", \"the\", \"bridge\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir une phrase en indices\n",
    "def numericalize(sentence, vocab):\n",
    "    return [vocab[bos_token]] + [vocab[token] for token in sentence.split()] + [vocab[eos_token]]\n",
    "\n",
    "# Fonction de traitement d'un lot\n",
    "def collate_fn(batch):\n",
    "    en_batch = [torch.tensor(numericalize(item[\"en\"], en_vocab)) for item in batch]\n",
    "    ye_batch = [torch.tensor(numericalize(item[\"ye\"], ye_vocab)) for item in batch]\n",
    "    \n",
    "    en_batch = pad_sequence(en_batch, padding_value=en_vocab[pad_token])\n",
    "    ye_batch = pad_sequence(ye_batch, padding_value=ye_vocab[pad_token])\n",
    "    \n",
    "    return {\"en\": en_batch, \"ye\": ye_batch}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargeurs de données prêts!\n"
     ]
    }
   ],
   "source": [
    "# Création des chargeurs de données\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de l'encodeur\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du décodeur\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle Seq2Seq\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle initialisé!\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des hyperparamètres\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = len(en_vocab)\n",
    "output_dim = len(ye_vocab)\n",
    "emb_dim = 256\n",
    "hid_dim = 512\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "# Initialisation du modèle\n",
    "encoder = Encoder(input_dim, emb_dim, hid_dim, n_layers, dropout).to(device)\n",
    "decoder = Decoder(output_dim, emb_dim, hid_dim, n_layers, dropout).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=en_vocab[pad_token])\n",
    "\n",
    "print(\"Modèle initialisé!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entraînement\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in iterator:\n",
    "        src, trg = batch[\"en\"].to(device), batch[\"ye\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'évaluation\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src, trg = batch[\"en\"].to(device), batch[\"ye\"].to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1: Perte entraînement = 1.825, Perte validation = 1.197\n",
      "Époque 2: Perte entraînement = 0.751, Perte validation = 0.787\n",
      "Époque 3: Perte entraînement = 0.458, Perte validation = 0.637\n",
      "Époque 4: Perte entraînement = 0.385, Perte validation = 0.524\n",
      "Époque 5: Perte entraînement = 0.338, Perte validation = 0.513\n"
     ]
    }
   ],
   "source": [
    "# Boucle principale d'entraînement et d'évaluation\n",
    "epochs = 5\n",
    "clip = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "    print(f\"Époque {epoch+1}: Perte entraînement = {train_loss:.3f}, Perte validation = {valid_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dossier pour sauvegarder le modèle\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé à l'époque 5 avec une perte de validation de 0.513\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(save_dir, \"best_model.pth\")\n",
    "torch.save({\n",
    "    'epoch': epoch + 1,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': valid_loss,\n",
    "}, model_path)\n",
    "print(f\"Modèle sauvegardé à l'époque {epoch+1} avec une perte de validation de {valid_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle sauvegardé\n",
    "def load_model(model, optimizer, model_path=\"saved_models/best_model.pth\"):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Modèle chargé depuis l'époque {epoch} avec une perte de validation de {loss:.3f}\")\n",
    "    return model, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle chargé depuis l'époque 5 avec une perte de validation de 0.513\n"
     ]
    }
   ],
   "source": [
    "model_path=\"saved_models/best_model.pth\"\n",
    "model, optimizer = load_model(model, optimizer, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, en_vocab, ye_vocab, device, max_length=50):\n",
    "    \"\"\"Traduit une phrase de l'anglais vers le yemba.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenisation et conversion en indices\n",
    "    tokens = sentence.lower().split()\n",
    "    numericalized = [en_vocab[\"<bos>\"]]\n",
    "    \n",
    "    # Ajouter chaque token avec un fallback sur <unk> si le mot n'existe pas\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            numericalized.append(en_vocab[token])  # Tentative d'accès direct au vocabulaire\n",
    "        except KeyError:\n",
    "            numericalized.append(en_vocab[\"<unk>\"]) # Si le mot n'est pas trouvé, ajouter <unk>\n",
    "    numericalized.append(en_vocab[\"<eos>\"])\n",
    "    \n",
    "    # Conversion en tenseur PyTorch\n",
    "    src_tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device)\n",
    "    \n",
    "    # Passage dans l'encodeur\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor)\n",
    "    \n",
    "    # Décodage itératif\n",
    "    trg_indexes = [ye_vocab[\"<bos>\"]]\n",
    "    \n",
    "    for _ in range(max_length):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        \n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        \n",
    "        if pred_token == ye_vocab[\"<eos>\"]:\n",
    "            break\n",
    "  \n",
    "    trg_tokens = [ye_vocab.lookup_token(idx) for idx in trg_indexes]   # Conversion des indices en mots\n",
    "    \n",
    "    return \" \".join(trg_tokens[1:-1])  # Exclure <bos> et <eos>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrases en anglais</th>\n",
       "      <th>Phrases en swahili</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The man is sitting.</td>\n",
       "      <td>Mwanamume huyo ameketi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The people are outside.</td>\n",
       "      <td>Watu wako nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The woman is wearing white.</td>\n",
       "      <td>Mwanamke huyo amevaa mavazi meupe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is standing.</td>\n",
       "      <td>Mwanamume mmoja amesimama.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A man wearing a white shirt with black dot is ...</td>\n",
       "      <td>Mwanamume aliyevalia shati jeupe lenye nukta n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A man is sleeping.</td>\n",
       "      <td>Mwanamume fulani amelala.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A man is outside.</td>\n",
       "      <td>Kuna mwanamume nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>There are multiple people present.</td>\n",
       "      <td>Kuna watu wengi waliopo.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The man is sitting down.</td>\n",
       "      <td>Mwanamume huyo ameketi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Two dogs are playing.</td>\n",
       "      <td>Mbwa wawili wanacheza.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>People are outside.</td>\n",
       "      <td>Watu wako nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bicyclists waiting at an intersection.</td>\n",
       "      <td>Waendesha baiskeli wakisubiri kwenye makutano.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A woman is inside.</td>\n",
       "      <td>Kuna mwanamke ndani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A man is sitting down.</td>\n",
       "      <td>Mwanamume fulani ameketi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The man is standing.</td>\n",
       "      <td>Mwanamume huyo amesimama.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>There are people outside.</td>\n",
       "      <td>Kuna watu nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A dog is swimming.</td>\n",
       "      <td>Mbwa anaogelea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The man is indoors.</td>\n",
       "      <td>Mwanamume huyo yuko ndani ya nyumba.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Two people are sitting on a bench.</td>\n",
       "      <td>Watu wawili wameketi kwenye benchi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A man is walking down the street.</td>\n",
       "      <td>Mwanamume fulani anatembea barabarani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A man is swimming.</td>\n",
       "      <td>Mwanamume fulani anaogelea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>A man is playing the guitar.</td>\n",
       "      <td>Mwanamume fulani anapiga gitaa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Two men wearing bright green shirts are lookin...</td>\n",
       "      <td>Wanaume wawili waliovalia mashati ya rangi ya ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The man is outside.</td>\n",
       "      <td>Mwanamume huyo yuko nje.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A man wearing green shoes lounges outdoors.</td>\n",
       "      <td>Mwanamume aliyevaa viatu vya kijani-kibichi an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The people are inside.</td>\n",
       "      <td>Watu wako ndani.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Man stacking wooden crates on top of each other.</td>\n",
       "      <td>Mwanamume akisimamisha masanduku ya mbao juu y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>There are people outdoors.</td>\n",
       "      <td>Kuna watu nje.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Phrases en anglais  \\\n",
       "0                                 The man is sitting.   \n",
       "1                             The people are outside.   \n",
       "2                         The woman is wearing white.   \n",
       "4                                  A man is standing.   \n",
       "5   A man wearing a white shirt with black dot is ...   \n",
       "7                                  A man is sleeping.   \n",
       "8                                   A man is outside.   \n",
       "9                  There are multiple people present.   \n",
       "10                           The man is sitting down.   \n",
       "11                              Two dogs are playing.   \n",
       "12                                People are outside.   \n",
       "13             Bicyclists waiting at an intersection.   \n",
       "14                                 A woman is inside.   \n",
       "15                             A man is sitting down.   \n",
       "16                               The man is standing.   \n",
       "17                          There are people outside.   \n",
       "22                                 A dog is swimming.   \n",
       "25                                The man is indoors.   \n",
       "26                 Two people are sitting on a bench.   \n",
       "27                  A man is walking down the street.   \n",
       "31                                 A man is swimming.   \n",
       "32                       A man is playing the guitar.   \n",
       "34  Two men wearing bright green shirts are lookin...   \n",
       "35                                The man is outside.   \n",
       "37        A man wearing green shoes lounges outdoors.   \n",
       "40                             The people are inside.   \n",
       "43   Man stacking wooden crates on top of each other.   \n",
       "49                         There are people outdoors.   \n",
       "\n",
       "                                   Phrases en swahili  \n",
       "0                             Mwanamume huyo ameketi.  \n",
       "1                                      Watu wako nje.  \n",
       "2                  Mwanamke huyo amevaa mavazi meupe.  \n",
       "4                          Mwanamume mmoja amesimama.  \n",
       "5   Mwanamume aliyevalia shati jeupe lenye nukta n...  \n",
       "7                           Mwanamume fulani amelala.  \n",
       "8                                 Kuna mwanamume nje.  \n",
       "9                            Kuna watu wengi waliopo.  \n",
       "10                            Mwanamume huyo ameketi.  \n",
       "11                             Mbwa wawili wanacheza.  \n",
       "12                                     Watu wako nje.  \n",
       "13     Waendesha baiskeli wakisubiri kwenye makutano.  \n",
       "14                               Kuna mwanamke ndani.  \n",
       "15                          Mwanamume fulani ameketi.  \n",
       "16                          Mwanamume huyo amesimama.  \n",
       "17                                     Kuna watu nje.  \n",
       "22                                    Mbwa anaogelea.  \n",
       "25               Mwanamume huyo yuko ndani ya nyumba.  \n",
       "26                Watu wawili wameketi kwenye benchi.  \n",
       "27             Mwanamume fulani anatembea barabarani.  \n",
       "31                        Mwanamume fulani anaogelea.  \n",
       "32                    Mwanamume fulani anapiga gitaa.  \n",
       "34  Wanaume wawili waliovalia mashati ya rangi ya ...  \n",
       "35                           Mwanamume huyo yuko nje.  \n",
       "37  Mwanamume aliyevaa viatu vya kijani-kibichi an...  \n",
       "40                                   Watu wako ndani.  \n",
       "43  Mwanamume akisimamisha masanduku ya mbao juu y...  \n",
       "49                                     Kuna watu nje.  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = test_data['en'][:50]\n",
    "traduction = test_data['ye'][:50]\n",
    "df_phrases = pd.DataFrame({\"Phrases en anglais\": phrases, \"Phrases en swahili\": traduction})\n",
    "df_phrase = df_phrases.drop_duplicates()\n",
    "df_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The people are outside.', 'Watu wako nje.')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[1][\"en\"]\n",
    "expected_translation = test_data[1][\"ye\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduction: Watu wako nje.\n"
     ]
    }
   ],
   "source": [
    "translation = translate_sentence(sentence, model, en_vocab, ye_vocab, device)\n",
    "print(\"Traduction:\", translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traduction: Watu wako nje.\n"
     ]
    }
   ],
   "source": [
    "# Exemple de traduction\n",
    "translation = translate_sentence(sentence, model, en_vocab, ye_vocab, device)\n",
    "print(\"Traduction:\", translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase: The man is sitting.\n",
      "Réponse: Mwanamume huyo ameketi.\n",
      "Traduction: Mwanamume huyo ameketi.\n",
      "Phrase: The people are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: The woman is wearing white.\n",
      "Réponse: Mwanamke huyo amevaa mavazi meupe.\n",
      "Traduction: Mwanamke huyo amevaa mavazi meupe.\n",
      "Phrase: The people are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: A man is standing.\n",
      "Réponse: Mwanamume mmoja amesimama.\n",
      "Traduction: Mwanamume mmoja amesimama.\n",
      "Phrase: A man wearing a white shirt with black dot is holding a microphone as he stands in front of a background of black with white symbols on it.\n",
      "Réponse: Mwanamume aliyevalia shati jeupe lenye nukta nyeusi anashikilia kipaza sauti huku akiwa amesimama mbele ya mandhari nyeusi yenye alama nyeupe.\n",
      "Traduction: kijana aliyevalia suruali ya rangi ya kahawia na shati la kijani-kibichi anatazama juu ya ukuta wenye urefu wa kiuno unaotenganisha jikoni na chumba cha kuishi cha nyumba.\n",
      "Phrase: The people are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: A man is sleeping.\n",
      "Réponse: Mwanamume fulani amelala.\n",
      "Traduction: mtu amelala.\n",
      "Phrase: A man is outside.\n",
      "Réponse: Kuna mwanamume nje.\n",
      "Traduction: Kuna mwanamume nje.\n",
      "Phrase: There are multiple people present.\n",
      "Réponse: Kuna watu wengi waliopo.\n",
      "Traduction: Kuna watu wengi waliopo.\n",
      "Phrase: The man is sitting down.\n",
      "Réponse: Mwanamume huyo ameketi.\n",
      "Traduction: Mwanamume fulani ameketi.\n",
      "Phrase: Two dogs are playing.\n",
      "Réponse: Mbwa wawili wanacheza.\n",
      "Traduction: mbwa wawili wanacheza.\n",
      "Phrase: People are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: Bicyclists waiting at an intersection.\n",
      "Réponse: Waendesha baiskeli wakisubiri kwenye makutano.\n",
      "Traduction: Waendesha baiskeli wakisubiri kwenye makutano.\n",
      "Phrase: A woman is inside.\n",
      "Réponse: Kuna mwanamke ndani.\n",
      "Traduction: Kuna mwanamke ndani.\n",
      "Phrase: A man is sitting down.\n",
      "Réponse: Mwanamume fulani ameketi.\n",
      "Traduction: Mwanamume fulani ameketi.\n",
      "Phrase: The man is standing.\n",
      "Réponse: Mwanamume huyo amesimama.\n",
      "Traduction: Mwanamume huyo amesimama.\n",
      "Phrase: There are people outside.\n",
      "Réponse: Kuna watu nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: The people are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n",
      "Phrase: The people are outside.\n",
      "Réponse: Watu wako nje.\n",
      "Traduction: Watu wako nje.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    sentence = test_data[i][\"en\"]\n",
    "    expected_translation = test_data[i][\"ye\"]\n",
    "    translation = translate_sentence(sentence, model, en_vocab, ye_vocab, device)\n",
    "    print(\"Phrase:\", sentence)\n",
    "    print(\"Réponse:\", expected_translation)\n",
    "    print(\"Traduction:\", translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface utilisateur avec Streamlit\n",
    "st.title(\"Chatbot de Traduction Anglais → Swahili\")\n",
    "st.write(\"Entrez une phrase en anglais et obtenez la traduction en Swahili.\")\n",
    "\n",
    "# Saisie utilisateur\n",
    "sentence = st.text_input(\"Entrez votre texte en anglais :\", \"\")\n",
    "\n",
    "if st.button(\"Traduire\"):\n",
    "    if sentence:\n",
    "        translation = translate_sentence(sentence)\n",
    "        st.success(f\"**Traduction en Swahili :** {translation}\")\n",
    "    else:\n",
    "        st.warning(\"Veuillez entrer une phrase en anglais.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_nlpevn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
